{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.8.2", "generated_at": "2024-06-18T05:17:11.144093Z", "invocation_id": "145d5852-e886-4678-a32c-524278d14abf", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.380956Z", "completed_at": "2024-06-18T05:17:10.476554Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.477582Z", "completed_at": "2024-06-18T05:17:10.477582Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.20728468894958496, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_columns", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as parent_unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as data_type\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as database_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as schema_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as table_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as resource_type\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_columns\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.291294Z", "completed_at": "2024-06-18T05:17:10.478578Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.480544Z", "completed_at": "2024-06-18T05:17:10.480544Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.21324610710144043, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.data_monitoring_metrics", "compiled": true, "compiled_code": "\n\n\n    \n    \n        \n    \n    select * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as full_table_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as column_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metric_name\n\n,\n                \n        cast(123456789.99 as float) as metric_value\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as source_value\n\n,\n                cast('2091-02-17' as timestamp) as bucket_start\n\n,\n                cast('2091-02-17' as timestamp) as bucket_end\n\n,\n                \n        cast(123456789 as integer) as bucket_duration_hours\n\n,\n                cast('2091-02-17' as timestamp) as updated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as dimension\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as dimension_value\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metric_properties\n\n,\n                cast('2091-02-17' as timestamp) as created_at\n\n\n        ) as empty_table\n        where 1 = 0\n", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"data_monitoring_metrics\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.435955Z", "completed_at": "2024-06-18T05:17:10.479548Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.482545Z", "completed_at": "2024-06-18T05:17:10.482545Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.20925521850585938, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_exposures", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as maturity\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as type\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as owner_email\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as owner_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as url\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_columns\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as package_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as original_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as label\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as raw_queries\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_exposures\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.451578Z", "completed_at": "2024-06-18T05:17:10.481547Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.485543Z", "completed_at": "2024-06-18T05:17:10.485543Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.20925021171569824, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_invocations", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('this_is_just_a_long_dummy_string' as text) as invocation_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as job_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as job_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as job_run_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as run_started_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as run_completed_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                cast('2091-02-17' as timestamp) as created_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as command\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as dbt_version\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as elementary_version\n\n,\n                \n        cast (True as boolean) as full_refresh\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as invocation_vars\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as vars\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as target_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as target_database\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as target_schema\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as target_profile_name\n\n,\n                \n        cast(123456789 as integer) as threads\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as selected\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as yaml_selector\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as project_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as project_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as env\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as env_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as cause_category\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as cause\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as pull_request_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as git_sha\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as orchestrator\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as dbt_user\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as job_url\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as job_run_url\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as account_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as target_adapter_specific_fields\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_invocations\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.491580Z", "completed_at": "2024-06-18T05:17:10.538553Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.630173Z", "completed_at": "2024-06-18T05:17:10.630173Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.1466233730316162, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_metrics", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as label\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as model\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as type\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as sql\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as timestamp\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as filters\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as time_grains\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as dimensions\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as package_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as original_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_metrics\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.510554Z", "completed_at": "2024-06-18T05:17:10.632135Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.635138Z", "completed_at": "2024-06-18T05:17:10.635138Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.1465909481048584, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_models", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as alias\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as checksum\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as materialization\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as owner\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as database_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as schema_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as package_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as original_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as patch_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_models\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.539553Z", "completed_at": "2024-06-18T05:17:10.636143Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.640140Z", "completed_at": "2024-06-18T05:17:10.640140Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.15059661865234375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_run_results", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('this_is_just_a_long_dummy_string' as text) as model_execution_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as invocation_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                cast('2091-02-17' as timestamp) as created_at\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as message\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as status\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as resource_type\n\n,\n                \n        cast(123456789.99 as float) as execution_time\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as execute_started_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as execute_completed_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as compile_started_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as compile_completed_at\n\n,\n                \n        cast(31474836478 as bigint) as rows_affected\n\n,\n                \n        cast (True as boolean) as full_refresh\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as compiled_code\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as query_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as thread_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as materialization\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as adapter_response\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_run_results\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.615089Z", "completed_at": "2024-06-18T05:17:10.637137Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.642650Z", "completed_at": "2024-06-18T05:17:10.642650Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.13510584831237793, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_seeds", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as alias\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as checksum\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as owner\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as database_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as schema_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as package_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as original_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_seeds\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.647662Z", "completed_at": "2024-06-18T05:17:10.687660Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.730710Z", "completed_at": "2024-06-18T05:17:10.730710Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.09353256225585938, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_snapshots", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as alias\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as checksum\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as materialization\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as owner\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as database_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as schema_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as package_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as original_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as patch_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_snapshots\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.665664Z", "completed_at": "2024-06-18T05:17:10.731670Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.736670Z", "completed_at": "2024-06-18T05:17:10.736670Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.09200930595397949, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_source_freshness_results", "compiled": true, "compiled_code": "\n\n\n    select * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as source_freshness_execution_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as max_loaded_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as snapshotted_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                cast('2091-02-17' as timestamp) as created_at\n\n,\n                \n        cast(123456789.99 as float) as max_loaded_at_time_ago_in_s\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as status\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as error\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as compile_started_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as compile_completed_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as execute_started_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as execute_completed_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as invocation_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as warn_after\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as error_after\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as filter\n\n\n        ) as empty_table\n        where 1 = 0\n", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_source_freshness_results\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.688659Z", "completed_at": "2024-06-18T05:17:10.735676Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.739676Z", "completed_at": "2024-06-18T05:17:10.739676Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0769810676574707, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_sources", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as database_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as schema_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as source_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as identifier\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as loaded_at_field\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as freshness_warn_after\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as freshness_error_after\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as freshness_filter\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as freshness_description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as relation_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as owner\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as package_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as original_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as path\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as source_description\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_sources\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.709658Z", "completed_at": "2024-06-18T05:17:10.738671Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.742707Z", "completed_at": "2024-06-18T05:17:10.742707Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.07904314994812012, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_tests", "compiled": true, "compiled_code": "\n\nselect * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as database_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as schema_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as short_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as alias\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as test_column_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as severity\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as warn_if\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as error_if\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as test_params\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as test_namespace\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as model_tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as model_owners\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as meta\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as parent_model_unique_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as package_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as type\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as original_path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as path\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as generated_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as metadata_hash\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as quality_dimension\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_tests\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.746889Z", "completed_at": "2024-06-18T05:17:10.772892Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.795921Z", "completed_at": "2024-06-18T05:17:10.795921Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.05821347236633301, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.elementary_test_results", "compiled": true, "compiled_code": "\n\n\n    select * from (\n            select\n            \n                \n        cast('this_is_just_a_long_dummy_string' as text) as id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as data_issue_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as test_execution_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as test_unique_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as model_unique_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as invocation_id\n\n,\n                cast('2091-02-17' as timestamp) as detected_at\n\n,\n                cast('2091-02-17' as timestamp) as created_at\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as database_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as schema_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as table_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as column_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as test_type\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as test_sub_type\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as test_results_description\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as owners\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as tags\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as test_results_query\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as other\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as test_name\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as test_params\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as severity\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as status\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as test_short_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as test_alias\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as result_rows\n\n,\n                \n        cast(31474836478 as bigint) as failed_row_count\n\n\n        ) as empty_table\n        where 1 = 0\n", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"elementary_test_results\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.773887Z", "completed_at": "2024-06-18T05:17:10.805889Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.808889Z", "completed_at": "2024-06-18T05:17:10.808889Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.0630028247833252, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.metadata", "compiled": true, "compiled_code": "\n\nSELECT\n    '0.15.2' as dbt_pkg_version", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"metadata\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.784885Z", "completed_at": "2024-06-18T05:17:10.807887Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.810887Z", "completed_at": "2024-06-18T05:17:10.810887Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0429995059967041, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.schema_columns_snapshot", "compiled": true, "compiled_code": "\n\n\n    select * from (\n            select\n            \n                \n        cast('dummy_string' as varchar(4096)) as column_state_id\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as full_column_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as full_table_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as column_name\n\n,\n                \n        cast('dummy_string' as varchar(4096)) as data_type\n\n,\n                \n        cast (True as boolean) as is_new\n\n,\n                cast('2091-02-17' as timestamp) as detected_at\n\n,\n                cast('2091-02-17' as timestamp) as created_at\n\n\n        ) as empty_table\n        where 1 = 0\n", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"schema_columns_snapshot\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.797885Z", "completed_at": "2024-06-18T05:17:10.809891Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.825887Z", "completed_at": "2024-06-18T05:17:10.825887Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.05499982833862305, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.my_new_project.dq-check", "compiled": true, "compiled_code": "\n\n    select index, policy_id, master_policy_id, \n    policy_number, status_code\n    from public.\"Policy\"", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv\".\"dq-check\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.812890Z", "completed_at": "2024-06-18T05:17:10.830904Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.833900Z", "completed_at": "2024-06-18T05:17:10.833900Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02701282501220703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "operation.elementary.elementary-on-run-end-0", "compiled": true, "compiled_code": "\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.857418Z", "completed_at": "2024-06-18T05:17:10.910416Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.913417Z", "completed_at": "2024-06-18T05:17:10.913417Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.08351325988769531, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.metrics_anomaly_score", "compiled": true, "compiled_code": "\n\nwith data_monitoring_metrics as (\n\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"data_monitoring_metrics\"\n\n),\n\ntime_window_aggregation as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        metric_value,\n        source_value,\n        bucket_start,\n        bucket_end,\n        bucket_duration_hours,\n        updated_at,\n        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,\n        stddev(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,\n        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,\n        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,\n        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start\n    from data_monitoring_metrics\n    group by 1,2,3,4,5,6,7,8,9,10,11,12\n),\n\nmetrics_anomaly_score as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        case\n            when training_stddev is null then null\n            when training_stddev = 0 then 0\n            else (metric_value - training_avg) / (training_stddev)\n        end as anomaly_score,\n        metric_value as latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        max(updated_at) as updated_at\n    from time_window_aggregation\n        where\n            metric_value is not null\n            and training_avg is not null\n            and bucket_end >= \n    cast(date_trunc('day', \n    current_timestamp::timestamp\n) as timestamp) + cast(-7 as integer) * INTERVAL '1 day'\n\n    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\n    order by bucket_end desc\n\n\n),\n\nfinal as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        anomaly_score,\n        latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        updated_at,\n        case\n            when abs(anomaly_score) > 3 then true\n            else false end\n        as is_anomaly\n    from metrics_anomaly_score\n)\n\nselect * from final", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"metrics_anomaly_score\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.834901Z", "completed_at": "2024-06-18T05:17:10.911421Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.943002Z", "completed_at": "2024-06-18T05:17:10.943002Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.11615514755249023, "adapter_response": {}, "message": null, "failures": null, "unique_id": "operation.elementary.elementary-on-run-start-0", "compiled": true, "compiled_code": "\n  \n  \n\n  \n  \n  \n\n  \n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.900456Z", "completed_at": "2024-06-18T05:17:10.943002Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.946010Z", "completed_at": "2024-06-18T05:17:10.946010Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.11310744285583496, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.monitors_runs", "compiled": true, "compiled_code": "\n\nwith data_monitoring_metrics as (\n\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"data_monitoring_metrics\"\n\n),\n\nmax_bucket_end as (\n\n    select full_table_name,\n           column_name,\n           metric_name,\n           metric_properties,\n           max(bucket_end) as last_bucket_end,\n           min(bucket_end) as first_bucket_end\n    from data_monitoring_metrics\n    group by 1,2,3,4\n\n)\n\nselect * from max_bucket_end", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"monitors_runs\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.914453Z", "completed_at": "2024-06-18T05:17:10.949014Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.953010Z", "completed_at": "2024-06-18T05:17:10.953010Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.04555511474609375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.job_run_results", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith jobs as (\n  select\n    job_name,\n    job_id,\n    job_run_id,\n    \nmin(cast(run_started_at as timestamp))\n as job_run_started_at,\n    \nmax(cast(run_completed_at as timestamp))\n as job_run_completed_at,\n    \n    \n        (\n        (\n        (\n        ((\nmax(cast(run_completed_at as timestamp))\n)::date - (\nmin(cast(run_started_at as timestamp))\n)::date)\n     * 24 + date_part('hour', (\nmax(cast(run_completed_at as timestamp))\n)::timestamp) - date_part('hour', (\nmin(cast(run_started_at as timestamp))\n)::timestamp))\n     * 60 + date_part('minute', (\nmax(cast(run_completed_at as timestamp))\n)::timestamp) - date_part('minute', (\nmin(cast(run_started_at as timestamp))\n)::timestamp))\n     * 60 + floor(date_part('second', (\nmax(cast(run_completed_at as timestamp))\n)::timestamp)) - floor(date_part('second', (\nmin(cast(run_started_at as timestamp))\n)::timestamp)))\n    \n as job_run_execution_time\n  from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_invocations\"\n  where job_id is not null\n  group by job_name, job_id, job_run_id\n)\n\nselect\n  job_name as name,\n  job_id as id,\n  job_run_id as run_id,\n  job_run_started_at as run_started_at,\n  job_run_completed_at as run_completed_at,\n  job_run_execution_time as run_execution_time\nfrom jobs", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"job_run_results\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.956010Z", "completed_at": "2024-06-18T05:17:10.987011Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:10.989010Z", "completed_at": "2024-06-18T05:17:10.989010Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.04099702835083008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.model_run_results", "compiled": true, "compiled_code": "\n\nwith dbt_run_results as (\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_run_results\"\n),\n\ndbt_models as (\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_models\"\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.adapter_response,\n    run_results.thread_id,\n    models.database_name,\n    models.schema_name,\n    coalesce(run_results.materialization, models.materialization) as materialization,\n    models.tags,\n    models.package_name,\n    models.path,\n    models.original_path,\n    models.owner,\n    models.alias,\n    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,\n    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY \n    date_trunc('day', cast(run_results.generated_at as timestamp))\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_first_invocation_of_the_day,\n    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY \n    date_trunc('day', cast(run_results.generated_at as timestamp))\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_last_invocation_of_the_day\n    \nFROM dbt_run_results run_results\nJOIN dbt_models models ON run_results.unique_id = models.unique_id", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"model_run_results\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.969011Z", "completed_at": "2024-06-18T05:17:10.991008Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.001011Z", "completed_at": "2024-06-18T05:17:11.001011Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.04999971389770508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.snapshot_run_results", "compiled": true, "compiled_code": "\n\nwith dbt_run_results as (\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_run_results\"\n),\n\ndbt_snapshots as (\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_snapshots\"\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.adapter_response,\n    run_results.thread_id,\n    snapshots.database_name,\n    snapshots.schema_name,\n    coalesce(run_results.materialization, snapshots.materialization) as materialization,\n    snapshots.tags,\n    snapshots.package_name,\n    snapshots.path,\n    snapshots.original_path,\n    snapshots.owner,\n    snapshots.alias\nFROM dbt_run_results run_results\nJOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"snapshot_run_results\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.977015Z", "completed_at": "2024-06-18T05:17:11.000010Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.004020Z", "completed_at": "2024-06-18T05:17:11.004020Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.05001091957092285, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.alerts_dbt_source_freshness", "compiled": true, "compiled_code": "\n\nwith results as (\n  select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_source_freshness_results\"\n),\n\nsources as (\n  select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_sources\"\n)\n\nselect\n  results.source_freshness_execution_id as alert_id,\n  results.max_loaded_at,\n  results.snapshotted_at,\n  cast(results.generated_at as timestamp) as detected_at,\n  results.max_loaded_at_time_ago_in_s,\n  results.status,\n  results.error,\n  results.warn_after,\n  results.error_after,\n  results.filter,\n  sources.unique_id,\n  sources.database_name,\n  sources.schema_name,\n  sources.source_name,\n  sources.identifier,\n  sources.tags,\n  sources.meta,\n  sources.owner,\n  sources.package_name,\n  sources.path,\n  -- These columns below are deprecated. We add them since this view\n  -- was used to be loaded into an incremental model with those columns, their names were later changed\n  -- and Databricks doesn't respect `on_schema_change = 'append_new_columns'` properly, as described here -\n  -- https://docs.databricks.com/en/delta/update-schema.html#automatic-schema-evolution-for-delta-lake-merge\n  results.error_after as freshness_error_after,\n  results.warn_after as freshness_warn_after,\n  results.filter as freshness_filter\nfrom results\njoin sources on results.unique_id = sources.unique_id\nwhere True and lower(status) != 'pass'", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"alerts_dbt_source_freshness\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:10.992010Z", "completed_at": "2024-06-18T05:17:11.007011Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.010010Z", "completed_at": "2024-06-18T05:17:11.010010Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.03399801254272461, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.dbt_artifacts_hashes", "compiled": true, "compiled_code": "\n\n\n\n\nselect\n  'dbt_models' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_models\"\n union all \n\nselect\n  'dbt_tests' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_tests\"\n union all \n\nselect\n  'dbt_sources' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_sources\"\n union all \n\nselect\n  'dbt_snapshots' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_snapshots\"\n union all \n\nselect\n  'dbt_metrics' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_metrics\"\n union all \n\nselect\n  'dbt_exposures' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_exposures\"\n union all \n\nselect\n  'dbt_seeds' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_seeds\"\n union all \n\nselect\n  'dbt_columns' as artifacts_model,\n   metadata_hash\nfrom \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_columns\"\n\n\norder by metadata_hash", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"dbt_artifacts_hashes\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.011014Z", "completed_at": "2024-06-18T05:17:11.033021Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.042022Z", "completed_at": "2024-06-18T05:17:11.042022Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.04001140594482422, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.alerts_anomaly_detection", "compiled": true, "compiled_code": "\n\nwith elementary_test_results as (\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"elementary_test_results\"\n),\n\nalerts_anomaly_detection as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'anomaly_detection'\n)\n\nselect * from alerts_anomaly_detection", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"alerts_anomaly_detection\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.025015Z", "completed_at": "2024-06-18T05:17:11.044540Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.057534Z", "completed_at": "2024-06-18T05:17:11.058535Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.04952526092529297, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.alerts_dbt_tests", "compiled": true, "compiled_code": "\n\nwith elementary_test_results as (\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"elementary_test_results\"\n),\n\nalerts_dbt_tests as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != 'pass'   and lower(status) != 'skipped'  and test_type = 'dbt_test'\n)\n\nselect * from alerts_dbt_tests", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"alerts_dbt_tests\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.034021Z", "completed_at": "2024-06-18T05:17:11.057534Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.060541Z", "completed_at": "2024-06-18T05:17:11.060541Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.040529727935791016, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.alerts_schema_changes", "compiled": true, "compiled_code": "\n\n\nwith elementary_test_results as (\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"elementary_test_results\"\n),\n\nalerts_schema_changes as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'schema_change'\n)\n\nselect * from alerts_schema_changes", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"alerts_schema_changes\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.044540Z", "completed_at": "2024-06-18T05:17:11.062539Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.066536Z", "completed_at": "2024-06-18T05:17:11.066536Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.03551769256591797, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.test_result_rows", "compiled": true, "compiled_code": "-- indexes are not supported in all warehouses, relevant to postgres only\n\n\n-- depends_on: \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"elementary_test_results\"\nselect * from (\n            select\n            \n                \n        cast('this_is_just_a_long_dummy_string' as text) as elementary_test_results_id\n\n,\n                \n        cast('this_is_just_a_long_dummy_string' as text) as result_row\n\n,\n                cast('2091-02-17' as timestamp) as detected_at\n\n,\n                cast('2091-02-17' as timestamp) as created_at\n\n\n        ) as empty_table\n        where 1 = 0", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"test_result_rows\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.068535Z", "completed_at": "2024-06-18T05:17:11.100541Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.116540Z", "completed_at": "2024-06-18T05:17:11.116540Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.05700254440307617, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.my_new_project.not_null_dq-check_policy_id.88e8ec368e", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect policy_id\nfrom \"Data_Migration_Pipeline\".\"dbt_hv\".\"dq-check\"\nwhere policy_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.088537Z", "completed_at": "2024-06-18T05:17:11.117574Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.128583Z", "completed_at": "2024-06-18T05:17:11.128583Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.06304574012756348, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.my_new_project.unique_dq-check_policy_id.e65e14d62b", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    policy_id as unique_field,\n    count(*) as n_records\n\nfrom \"Data_Migration_Pipeline\".\"dbt_hv\".\"dq-check\"\nwhere policy_id is not null\ngroup by policy_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.101571Z", "completed_at": "2024-06-18T05:17:11.130620Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.131586Z", "completed_at": "2024-06-18T05:17:11.131586Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.04904508590698242, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.anomaly_threshold_sensitivity", "compiled": true, "compiled_code": "\n\nwith metrics_anomaly_score as (\n\n    select * from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"metrics_anomaly_score\"\n\n),\n\nscore_sensitivity as (\n\n    select\n        full_table_name,\n        column_name,\n        metric_name,\n        latest_metric_value,\n        training_avg as metric_avg,\n        training_stddev as metric_stddev,\n        anomaly_score,\n        case when abs(anomaly_score) >= 1.5 then true else false end as \"is_anomaly_1_5\",\n        case when abs(anomaly_score) >= 2 then true else false end as \"is_anomaly_2\",\n        case when abs(anomaly_score) >= 2.5 then true else false end as \"is_anomaly_2_5\",\n        case when abs(anomaly_score) >= 3 then true else false end as \"is_anomaly_3\",\n        case when abs(anomaly_score) >= 3.5 then true else false end as \"is_anomaly_3_5\",\n        case when abs(anomaly_score) >= 4 then true else false end as \"is_anomaly_4\",\n        case when abs(anomaly_score) >= 4.5 then true else false end as \"is_anomaly_4_5\"\n    from metrics_anomaly_score\n    where abs(anomaly_score) >= 1.5\n\n)\n\nselect * from score_sensitivity", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"anomaly_threshold_sensitivity\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-06-18T05:17:11.119537Z", "completed_at": "2024-06-18T05:17:11.133581Z"}, {"name": "execute", "started_at": "2024-06-18T05:17:11.134586Z", "completed_at": "2024-06-18T05:17:11.134586Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.03501462936401367, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.elementary.alerts_dbt_models", "compiled": true, "compiled_code": "\n\nwith error_models as (\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias \n    from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"model_run_results\"\n  \n    union all\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias  \n  from \"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"snapshot_run_results\"\n)\n\n\nselect model_execution_id as alert_id,\n       unique_id,\n       cast(generated_at as timestamp) as detected_at,\n       database_name,\n       materialization,\n       path,\n       original_path,\n       schema_name,\n       message,\n       owner as owners,\n       tags,\n       alias,\n       status,\n       full_refresh\nfrom error_models\nwhere True and lower(status) != 'success'and lower(status) != 'skipped'", "relation_name": "\"Data_Migration_Pipeline\".\"dbt_hv_elementary\".\"alerts_dbt_models\""}], "elapsed_time": 4.301892995834351, "args": {"populate_cache": true, "select": [], "log_format_file": "debug", "compile": true, "defer": false, "log_file_max_bytes": 10485760, "project_dir": "C:\\Users\\hemapr\\OneDrive - Capgemini\\Documents\\dbt-trial", "printer_width": 80, "empty_catalog": false, "use_colors_file": true, "strict_mode": false, "which": "generate", "macro_debugging": false, "static": false, "send_anonymous_usage_stats": true, "profiles_dir": "C:\\Users\\hemapr\\.dbt", "require_explicit_package_overrides_for_builtin_materializations": false, "log_level": "info", "cache_selected_only": false, "enable_legacy_logger": false, "log_format": "default", "version_check": true, "source_freshness_run_project_hooks": false, "indirect_selection": "eager", "partial_parse": true, "print": true, "exclude": [], "partial_parse_file_diff": true, "invocation_command": "dbt docs generate", "quiet": false, "static_parser": true, "use_colors": true, "log_path": "C:\\Users\\hemapr\\OneDrive - Capgemini\\Documents\\dbt-trial\\logs", "introspect": true, "write_json": true, "vars": {}, "favor_state": false, "show_resource_report": false, "warn_error_options": {"include": [], "exclude": []}, "log_level_file": "debug", "require_resource_names_without_spaces": false}}